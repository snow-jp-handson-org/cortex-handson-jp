# =========================================================
# Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2
# AIã‚’ç”¨ã„ãŸé¡§å®¢ã®å£°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# Step2: é¡§å®¢ã®å£°åˆ†æãƒšãƒ¼ã‚¸
# =========================================================
# æ¦‚è¦: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®é«˜åº¦ãªåˆ†æã¨ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
# ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½: AI_CLASSIFY, AI_FILTER, AI_AGG, AI_SUMMARIZE_AGG, AI_SIMILARITY
# =========================================================
# Created by Tsubasa Kanno @Snowflake
# æœ€çµ‚æ›´æ–°: 2025/06/16
# =========================================================

import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.functions import col, lit
from datetime import datetime
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide")

# Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—
@st.cache_resource
def get_snowflake_session():
    return get_active_session()

session = get_snowflake_session()

# =========================================================
# å®šæ•°è¨­å®š
# =========================================================

# åˆ†æã‚«ãƒ†ã‚´ãƒª
ANALYSIS_CATEGORIES = [
    "å•†å“å“è³ª",
    "é…é€ã‚µãƒ¼ãƒ“ã‚¹", 
    "ä¾¡æ ¼",
    "ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹",
    "åº—èˆ—ç’°å¢ƒ",
    "ãã®ä»–"
]

# =========================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================
def check_table_exists(table_name: str) -> bool:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª"""
    try:
        result = session.sql(f"SHOW TABLES LIKE '{table_name}'").collect()
        if len(result) > 0:
            return True
    except:
        pass
    
    try:
        session.sql(f"SELECT 1 FROM {table_name} LIMIT 1").collect()
        return True
    except:
        pass
    
    return False

def get_table_count(table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
    try:
        result = session.sql(f"SELECT COUNT(*) as count FROM {table_name}").collect()
        return result[0]['COUNT']
    except:
        return 0

# =========================================================
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«
# =========================================================
st.title("ğŸ—£ï¸ Step2: é¡§å®¢ã®å£°åˆ†æ")
st.header("AISQLæ©Ÿèƒ½ã‚’ä½¿ã£ãŸé«˜åº¦ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿åˆ†æ")
st.markdown("---")

# =========================================================
# ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª
# =========================================================
st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª")

# å¿…è¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
required_tables = {
    "CUSTOMER_REVIEWS": "é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿",
    "CUSTOMER_ANALYSIS": "å‰å‡¦ç†æ¸ˆã¿åˆ†æãƒ‡ãƒ¼ã‚¿"
}

col1, col2 = st.columns(2)

table_status = {}
for table_name, description in required_tables.items():
    exists = check_table_exists(table_name)
    count = get_table_count(table_name) if exists else 0
    table_status[table_name] = {"exists": exists, "count": count}
    
    status_icon = "âœ…" if exists else "âŒ"
    
    if table_name == "CUSTOMER_REVIEWS":
        with col1:
            st.metric(
                f"{status_icon} {description}", 
                f"{count:,}ä»¶",
                help="å…ƒã®é¡§å®¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿"
            )
    else:
        with col2:
            st.metric(
                f"{status_icon} {description}", 
                f"{count:,}ä»¶",
                help="å‰å‡¦ç†æ¸ˆã¿ã®ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿"
            )

# å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
all_tables_exist = all(status["exists"] for status in table_status.values())

if not all_tables_exist:
    st.error("âš ï¸ å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Step1ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.markdown("---")

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: AISQLæ©Ÿèƒ½ç´¹ä»‹
# =========================================================
st.subheader("ğŸ§  ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: AISQLæ©Ÿèƒ½")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    **AISQLã®ä¸»è¦æ©Ÿèƒ½:**
    
    - `AI_CLASSIFY`: ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«åˆ†é¡
    - `AI_FILTER`: æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    - `AI_AGG`: é›†ç´„åˆ†æ
    - `AI_SIMILARITY`: é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¤œå‡º
    """)

with col2:
    st.markdown("""
    **åˆ†æã®æµã‚Œ:**
    
    1. ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    2. æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    3. è³¼å…¥ãƒãƒ£ãƒãƒ«åˆ¥ã«é›†ç´„åˆ†æ
    4. é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ¤œå‡º
    """)

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: AI_CLASSIFYåˆ†æ
# =========================================================
st.markdown("---")

@st.fragment
def section_2_classify():
    st.subheader("ğŸ·ï¸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: AI_CLASSIFY - ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«åˆ†é¡")
    
    if st.button("ğŸ·ï¸ AI_CLASSIFYå®Ÿè¡Œï¼ˆå…¨ä»¶ï¼‰", type="primary"):
        with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è‡ªå‹•åˆ†é¡ä¸­..."):
            try:
                # AI_CLASSIFYé–¢æ•°ã§ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆ:labelsã§JSONæŠ½å‡ºï¼‰
                category_query = """
                SELECT 
                    review_id,
                    review_text,
                    rating,
                    purchase_channel,
                    AI_CLASSIFY(
                        review_text, 
                        ARRAY_CONSTRUCT('å•†å“å“è³ª', 'é…é€ã‚µãƒ¼ãƒ“ã‚¹', 'ä¾¡æ ¼', 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹', 'åº—èˆ—ç’°å¢ƒ', 'ãã®ä»–')
                    ):labels[0]::string as category
                FROM CUSTOMER_REVIEWS 
                WHERE review_text IS NOT NULL
                """
                
                results = session.sql(category_query).collect()
                
                if results:
                    st.success(f"âœ… {len(results)}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†é¡å®Œäº†")
                    
                    df_results = pd.DataFrame([row.as_dict() for row in results])
                    st.session_state['classify_results'] = df_results
                    
                    # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã®å¯è¦–åŒ–
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        category_counts = df_results['CATEGORY'].value_counts()
                        fig = px.pie(
                            values=category_counts.values,
                            names=category_counts.index,
                            title="ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        fig = px.bar(
                            x=category_counts.index,
                            y=category_counts.values,
                            title="ã‚«ãƒ†ã‚´ãƒªåˆ¥ä»¶æ•°",
                            labels={"x": "ã‚«ãƒ†ã‚´ãƒª", "y": "ä»¶æ•°"}
                        )
                        st.plotly_chart(fig, use_container_width=True)
                
            except Exception as e:
                st.error(f"âŒ åˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # åˆ†é¡çµæœã®è©³ç´°åˆ†ææ©Ÿèƒ½
    if 'classify_results' in st.session_state:
        df_results = st.session_state['classify_results']
        
        st.markdown("---")
        st.markdown("#### ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æ")
        
        # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
        selected_category = st.selectbox(
            "åˆ†æã—ãŸã„ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ:",
            ["å…¨ã‚«ãƒ†ã‚´ãƒª"] + sorted(df_results['CATEGORY'].unique().tolist()),
            key="category_select"
        )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        if selected_category == "å…¨ã‚«ãƒ†ã‚´ãƒª":
            filtered_df = df_results
        else:
            filtered_df = df_results[df_results['CATEGORY'] == selected_category]
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¯¾è±¡ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(filtered_df)}ä»¶")
        with col2:
            avg_rating = filtered_df['RATING'].mean()
            st.metric("å¹³å‡è©•ä¾¡", f"{avg_rating:.2f}")
        with col3:
            if len(filtered_df) > 0:
                top_channel = filtered_df['PURCHASE_CHANNEL'].mode()[0]
                st.metric("ä¸»è¦ãƒãƒ£ãƒãƒ«", top_channel)
        
        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
        items_per_page = st.slider("1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®è¡¨ç¤ºä»¶æ•°:", 5, 50, 10, key="items_per_page")
        total_pages = max(1, (len(filtered_df) - 1) // items_per_page + 1)
        
        if total_pages > 1:
            current_page = st.selectbox(
                f"ãƒšãƒ¼ã‚¸é¸æŠ (å…¨{total_pages}ãƒšãƒ¼ã‚¸):",
                range(1, total_pages + 1),
                key="current_page"
            )
        else:
            current_page = 1
        
        # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        start_idx = (current_page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_data = filtered_df.iloc[start_idx:end_idx]
        
        for _, row in page_data.iterrows():
            with st.expander(f"ğŸ·ï¸ {row['CATEGORY']} | è©•ä¾¡: {row['RATING']} | {row['PURCHASE_CHANNEL']}"):
                st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼ID**: {row['REVIEW_ID']}")
                st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹**: {row['REVIEW_TEXT']}")

section_2_classify()

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: AI_FILTERåˆ†æ
# =========================================================
st.markdown("---")

@st.fragment
def section_3_filter():
    st.subheader("ğŸ” ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: AI_FILTER - ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    
    # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®å…¥åŠ›æ–¹æ³•é¸æŠ
    filter_input_type = st.radio(
        "ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®æŒ‡å®šæ–¹æ³•:",
        ["ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é¸æŠ", "è‡ªç”±å…¥åŠ›"],
        horizontal=True,
        key="filter_input_type"
    )
    
    if filter_input_type == "ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é¸æŠ":
        filter_options = [
            "é…é€ã‚„æ¢±åŒ…ã«é–¢ã™ã‚‹å•é¡ŒãŒè¨€åŠã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ",
            "å•†å“ã®å“è³ªã«æº€è¶³ã—ã¦ã„ã‚‹è¡¨ç¾ãŒå«ã¾ã‚Œã‚‹ã‹ï¼Ÿ",
            "ä¾¡æ ¼ã«é–¢ã™ã‚‹è¨€åŠãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ",
            "ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹ã‹ï¼Ÿ"
        ]
        selected_filter = st.selectbox("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’é¸æŠ:", filter_options)
    else:
        selected_filter = st.text_input(
            "ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’å…¥åŠ›:",
            placeholder="ä¾‹ï¼šæ–°å•†å“ã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹ã‹ï¼Ÿ",
            help="ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰æŠ½å‡ºã—ãŸã„æ¡ä»¶ã‚’è‡ªç„¶è¨€èªã§å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
    
    if st.button("ğŸ” AI_FILTERå®Ÿè¡Œï¼ˆå…¨ä»¶ï¼‰", type="primary"):
        if not selected_filter or selected_filter.strip() == "":
            st.error("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­..."):
                try:
                    # AI_FILTERé–¢æ•°ã§æ¡ä»¶ãƒãƒƒãƒãƒ³ã‚°ï¼ˆå…¨ä»¶å¯¾è±¡ï¼‰
                    filter_query = f"""
                    SELECT 
                        review_id,
                        review_text,
                        rating,
                        purchase_channel,
                        AI_FILTER(CONCAT('{selected_filter}: ', review_text)) as filter_result
                    FROM CUSTOMER_REVIEWS 
                    WHERE review_text IS NOT NULL
                    """
                    
                    results = session.sql(filter_query).collect()
                    
                    if results:
                        matched_results = [r for r in results if r['FILTER_RESULT']]
                        
                        st.success(f"âœ… {len(matched_results)}ä»¶ãŒæ¡ä»¶ã«ãƒãƒƒãƒã—ã¾ã—ãŸï¼ˆå…¨{len(results)}ä»¶ä¸­ï¼‰")
                        
                        if matched_results:
                            # ãƒãƒƒãƒç‡ã®å¯è¦–åŒ–
                            match_rate = len(matched_results) / len(results) * 100
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                fig = px.pie(
                                    values=[len(matched_results), len(results) - len(matched_results)],
                                    names=['ãƒãƒƒãƒ', 'éãƒãƒƒãƒ'],
                                    title=f"ãƒ•ã‚£ãƒ«ã‚¿çµæœ (ãƒãƒƒãƒç‡: {match_rate:.1f}%)"
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            
                            with col2:
                                # ãƒãƒ£ãƒãƒ«åˆ¥ãƒãƒƒãƒåˆ†æ
                                df_matched = pd.DataFrame([r.as_dict() for r in matched_results])
                                channel_counts = df_matched['PURCHASE_CHANNEL'].value_counts()
                                fig = px.bar(
                                    x=channel_counts.index,
                                    y=channel_counts.values,
                                    title="ãƒãƒ£ãƒãƒ«åˆ¥ãƒãƒƒãƒä»¶æ•°",
                                    labels={"x": "è³¼å…¥ãƒãƒ£ãƒãƒ«", "y": "ä»¶æ•°"}
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # ãƒãƒƒãƒã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è©³ç´°è¡¨ç¤º
                            st.markdown("#### ğŸ“ ãƒãƒƒãƒã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼è©³ç´°")
                            for result in matched_results[:20]:  # æœ€åˆã®20ä»¶ã®ã¿è¡¨ç¤º
                                data = result.as_dict()
                                
                                with st.expander(f"ğŸ“‹ ãƒ¬ãƒ“ãƒ¥ãƒ¼ID: {data['REVIEW_ID']} | è©•ä¾¡: {data['RATING']} | {data['PURCHASE_CHANNEL']}"):
                                    st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹**: {data['REVIEW_TEXT']}")
                                    st.success(f"**ãƒ•ã‚£ãƒ«ã‚¿çµæœ**: æ¡ä»¶ã«ãƒãƒƒãƒ")
                            
                            if len(matched_results) > 20:
                                st.info(f"ã•ã‚‰ã«{len(matched_results) - 20}ä»¶ã®ãƒãƒƒãƒã—ãŸçµæœãŒã‚ã‚Šã¾ã™ã€‚")
                        else:
                            st.info("æ¡ä»¶ã«ãƒãƒƒãƒã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    
                except Exception as e:
                    st.error(f"âŒ ãƒ•ã‚£ãƒ«ã‚¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

section_3_filter()

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: AI_AGGåˆ†æ
# =========================================================
st.markdown("---")

@st.fragment
def section_4_agg():
    st.subheader("ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: AI_AGG - è³¼å…¥ãƒãƒ£ãƒãƒ«åˆ¥é›†ç´„åˆ†æ")
    
    # é›†ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›æ–¹æ³•é¸æŠ
    agg_input_type = st.radio(
        "åˆ†æè¦³ç‚¹ã®æŒ‡å®šæ–¹æ³•:",
        ["ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é¸æŠ", "è‡ªç”±å…¥åŠ›"],
        horizontal=True,
        key="agg_input_type"
    )
    
    if agg_input_type == "ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰é¸æŠ":
        agg_prompts = [
            "å„ãƒãƒ£ãƒãƒ«ã§ç‰¹ã«è¨€åŠã•ã‚Œã¦ã„ã‚‹ç‰¹å¾´ã‚’ä¸€è¨€ã§è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚",
            "é¡§å®¢ã®ä¸»ãªä¸æº€ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "é¡§å®¢ã®ä¸»ãªæº€è¶³ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
            "æ”¹å–„ã™ã¹ãç‚¹ã‚’ä¸€ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚"
        ]
        selected_agg_prompt = st.selectbox("é›†ç´„åˆ†æã®è¦³ç‚¹ã‚’é¸æŠ:", agg_prompts)
    else:
        selected_agg_prompt = st.text_input(
            "åˆ†æè¦³ç‚¹ã‚’å…¥åŠ›:",
            placeholder="ä¾‹ï¼šã“ã®ãƒãƒ£ãƒãƒ«ã®ç‰¹å¾´çš„ãªå£ã‚³ãƒŸã®å‚¾å‘ã¯ï¼Ÿ",
            help="å„è³¼å…¥ãƒãƒ£ãƒãƒ«ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰åˆ†æã—ãŸã„è¦³ç‚¹ã‚’è‡ªç„¶è¨€èªã§å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
    
    if st.button("ğŸ“Š AI_AGGå®Ÿè¡Œ", type="primary"):
        if not selected_agg_prompt or selected_agg_prompt.strip() == "":
            st.error("åˆ†æè¦³ç‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("è³¼å…¥ãƒãƒ£ãƒãƒ«åˆ¥é›†ç´„åˆ†æå®Ÿè¡Œä¸­..."):
                try:
                    # AI_AGGé–¢æ•°ã§ãƒãƒ£ãƒãƒ«åˆ¥é›†ç´„åˆ†æï¼ˆTRANSLATEé–¢æ•°ã§æ—¥æœ¬èªåŒ–ï¼‰
                    agg_query = f"""
                    SELECT 
                        purchase_channel,
                        COUNT(*) as review_count,
                        AVG(rating) as avg_rating,
                        SNOWFLAKE.CORTEX.TRANSLATE(
                            AI_AGG(
                                review_text, 
                                '{selected_agg_prompt}'
                            ),
                            '',
                            'ja'
                        ) as channel_insights
                    FROM CUSTOMER_REVIEWS
                    WHERE review_text IS NOT NULL
                    GROUP BY purchase_channel
                    """
                    
                    results = session.sql(agg_query).collect()
                    
                    if results:
                        st.success(f"âœ… {len(results)}ã¤ã®è³¼å…¥ãƒãƒ£ãƒãƒ«ã®åˆ†æå®Œäº†")
                        
                        for result in results:
                            data = result.as_dict()
                            
                            with st.expander(f"ğŸ“ˆ {data['PURCHASE_CHANNEL']} ãƒãƒ£ãƒãƒ«"):
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{data['REVIEW_COUNT']}ä»¶")
                                    st.metric("å¹³å‡è©•ä¾¡", f"{data['AVG_RATING']:.2f}")
                                
                                with col2:
                                    st.markdown("**AIé›†ç´„åˆ†æçµæœ:**")
                                    st.write(data['CHANNEL_INSIGHTS'])
                    
                except Exception as e:
                    st.error(f"âŒ AI_AGGåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")

section_4_agg()

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: AI_SIMILARITYåˆ†æ
# =========================================================
st.markdown("---")

@st.fragment
def section_5_similarity():
    st.subheader("ğŸ”— ã‚»ã‚¯ã‚·ãƒ§ãƒ³5: AI_SIMILARITY - é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¤œå‡º")
    
    # åŸºæº–ã¨ãªã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å…¥åŠ›
    base_text = st.text_area(
        "åŸºæº–ã¨ãªã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›:",
        value="å•†å“ã®å“è³ªã¯ç´ æ™´ã‚‰ã—ã„ãŒã€é…é€ãŒé…ã‹ã£ãŸã€‚",
        height=80
    )
    
    similarity_threshold = st.slider("é¡ä¼¼åº¦é–¾å€¤:", 0.0, 1.0, 0.7, step=0.1)
    
    if st.button("ğŸ”— AI_SIMILARITYå®Ÿè¡Œï¼ˆå…¨ä»¶ï¼‰", type="primary"):
        with st.spinner("é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ¤œç´¢ä¸­..."):
            try:
                # AI_SIMILARITYé–¢æ•°ã§é¡ä¼¼åº¦è¨ˆç®—ï¼ˆå…¨ä»¶å¯¾è±¡ï¼‰
                similarity_query = f"""
                SELECT 
                    review_id,
                    review_text,
                    rating,
                    purchase_channel,
                    AI_SIMILARITY('{base_text}', review_text) as similarity_score
                FROM CUSTOMER_REVIEWS 
                WHERE review_text IS NOT NULL
                ORDER BY similarity_score DESC
                """
                
                results = session.sql(similarity_query).collect()
                
                if results:
                    # é–¾å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿
                    similar_reviews = [r for r in results if r['SIMILARITY_SCORE'] >= similarity_threshold]
                    
                    st.success(f"âœ… é¡ä¼¼åº¦{similarity_threshold}ä»¥ä¸Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’{len(similar_reviews)}ä»¶ç™ºè¦‹ï¼ˆå…¨{len(results)}ä»¶ä¸­ï¼‰")
                    
                    if similar_reviews:
                        # é¡ä¼¼åº¦åˆ†å¸ƒã®å¯è¦–åŒ–
                        df_similarity = pd.DataFrame([r.as_dict() for r in results])
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # é¡ä¼¼åº¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                            fig = px.histogram(
                                df_similarity,
                                x='SIMILARITY_SCORE',
                                nbins=20,
                                title="é¡ä¼¼åº¦åˆ†å¸ƒ",
                                labels={"x": "é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢", "y": "ä»¶æ•°"}
                            )
                            fig.add_vline(x=similarity_threshold, line_dash="dash", line_color="red", 
                                        annotation_text=f"é–¾å€¤: {similarity_threshold}")
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            # é–¾å€¤ä»¥ä¸Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒãƒ£ãƒãƒ«åˆ†å¸ƒ
                            df_filtered = pd.DataFrame([r.as_dict() for r in similar_reviews])
                            channel_counts = df_filtered['PURCHASE_CHANNEL'].value_counts()
                            fig = px.pie(
                                values=channel_counts.values,
                                names=channel_counts.index,
                                title=f"é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒãƒ£ãƒãƒ«åˆ†å¸ƒ"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®è©³ç´°è¡¨ç¤º
                        st.markdown("#### ğŸ”— é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼è©³ç´°ï¼ˆä¸Šä½15ä»¶ï¼‰")
                        for result in similar_reviews[:15]:
                            data = result.as_dict()
                            similarity = data['SIMILARITY_SCORE']
                            
                            # é¡ä¼¼åº¦ã«å¿œã˜ãŸè‰²åˆ†ã‘
                            if similarity >= 0.8:
                                similarity_color = "ğŸŸ¢"
                            elif similarity >= 0.6:
                                similarity_color = "ğŸŸ¡"
                            else:
                                similarity_color = "ğŸŸ "
                            
                            with st.expander(f"{similarity_color} ãƒ¬ãƒ“ãƒ¥ãƒ¼ID: {data['REVIEW_ID']} | é¡ä¼¼åº¦: {similarity:.3f} | {data['PURCHASE_CHANNEL']}"):
                                st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹**: {data['REVIEW_TEXT']}")
                                st.write(f"**è©•ä¾¡**: {data['RATING']}")
                                st.write(f"**é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢**: {similarity:.3f}")
                        
                        if len(similar_reviews) > 15:
                            st.info(f"ã•ã‚‰ã«{len(similar_reviews) - 15}ä»¶ã®é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚")
                    else:
                        st.info(f"é¡ä¼¼åº¦{similarity_threshold}ä»¥ä¸Šã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
            except Exception as e:
                st.error(f"âŒ é¡ä¼¼åº¦åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")

section_5_similarity()

# =========================================================
# ã‚»ã‚¯ã‚·ãƒ§ãƒ³6: çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ
# =========================================================
st.markdown("---")

@st.fragment
def section_6_integrated():
    st.subheader("ğŸš€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³6: çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    
    if st.button("ğŸš€ çµ±åˆåˆ†æå®Ÿè¡Œï¼ˆå…¨ä»¶ï¼‰", type="primary"):
        with st.spinner("çµ±åˆåˆ†æå®Ÿè¡Œä¸­..."):
            try:
                # è¤‡æ•°ã®AISQLã‚’çµ„ã¿åˆã‚ã›ãŸçµ±åˆåˆ†æï¼ˆå…¨ä»¶å¯¾è±¡ï¼‰
                # ã¾ãšåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                base_query = """
                SELECT 
                    review_id,
                    review_text,
                    rating,
                    purchase_channel,
                    SNOWFLAKE.CORTEX.SENTIMENT(review_text) as sentiment_score,
                    AI_CLASSIFY(
                        review_text, 
                        ARRAY_CONSTRUCT('å•†å“å“è³ª', 'é…é€ã‚µãƒ¼ãƒ“ã‚¹', 'ä¾¡æ ¼', 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹', 'åº—èˆ—ç’°å¢ƒ', 'ãã®ä»–')
                    ):labels[0]::string as category
                FROM CUSTOMER_REVIEWS 
                WHERE review_text IS NOT NULL
                """
                
                # AI_SUMMARIZE_AGGã‚’ä½¿ç”¨ã—ã¦ã‚«ãƒ†ã‚´ãƒªåˆ¥è¦ç´„ã‚’å–å¾—
                summary_query = """
                SELECT 
                    category,
                    purchase_channel,
                    SNOWFLAKE.CORTEX.TRANSLATE(
                        AI_SUMMARIZE_AGG(review_text),
                        '',
                        'ja'
                    ) as category_summary
                FROM (
                    SELECT 
                        review_text,
                        purchase_channel,
                        AI_CLASSIFY(
                            review_text, 
                            ARRAY_CONSTRUCT('å•†å“å“è³ª', 'é…é€ã‚µãƒ¼ãƒ“ã‚¹', 'ä¾¡æ ¼', 'ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹', 'åº—èˆ—ç’°å¢ƒ', 'ãã®ä»–')
                        ):labels[0]::string as category
                    FROM CUSTOMER_REVIEWS 
                    WHERE review_text IS NOT NULL
                )
                GROUP BY category, purchase_channel
                """
                
                # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                base_results = session.sql(base_query).collect()
                # ã‚«ãƒ†ã‚´ãƒªåˆ¥è¦ç´„ã‚’å–å¾—
                summary_results = session.sql(summary_query).collect()
                
                if base_results and summary_results:
                    df_base = pd.DataFrame([row.as_dict() for row in base_results])
                    df_summary = pd.DataFrame([row.as_dict() for row in summary_results])
                    
                    # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã¨ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                    df_results = df_base.merge(
                        df_summary, 
                        on=['CATEGORY', 'PURCHASE_CHANNEL'], 
                        how='left'
                    )
                    
                    # çµ±åˆåˆ†æçµæœã‚’session_stateã«ä¿å­˜
                    st.session_state['integrated_results'] = df_results
                    st.session_state['category_summaries'] = df_summary
                    
                    st.success(f"âœ… çµ±åˆåˆ†æå®Œäº†ï¼ˆ{len(base_results)}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€{len(summary_results)}ã®ã‚«ãƒ†ã‚´ãƒªåˆ¥è¦ç´„ï¼‰")
                
            except Exception as e:
                st.error(f"âŒ çµ±åˆåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # çµ±åˆåˆ†æçµæœã®è¡¨ç¤º
    if 'integrated_results' in st.session_state:
        df_results = st.session_state['integrated_results']
        
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®å®šç¾©èª¬æ˜
        st.info("""
        **ğŸ“Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢å®šç¾©:**
        - **ãƒã‚¸ãƒ†ã‚£ãƒ–**: 0.1ä»¥ä¸Š ğŸ˜Š
        - **ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«**: -0.1ï½0.1 ğŸ˜  
        - **ãƒã‚¬ãƒ†ã‚£ãƒ–**: -0.1æœªæº€ ğŸ˜
        """)
        
        # å…¨ä½“çµ±è¨ˆã®å¯è¦–åŒ–
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_sentiment = df_results['SENTIMENT_SCORE'].mean()
            st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{avg_sentiment:.3f}")
        
        with col2:
            positive_ratio = (df_results['SENTIMENT_SCORE'] > 0.1).mean() * 100
            st.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡", f"{positive_ratio:.1f}%")
        
        with col3:
            negative_ratio = (df_results['SENTIMENT_SCORE'] < -0.1).mean() * 100
            st.metric("ãƒã‚¬ãƒ†ã‚£ãƒ–ç‡", f"{negative_ratio:.1f}%")
        
        with col4:
            most_common_category = df_results['CATEGORY'].mode()[0]
            st.metric("æœ€å¤šã‚«ãƒ†ã‚´ãƒª", most_common_category)
        
        # æ„Ÿæƒ…ã¨ã‚«ãƒ†ã‚´ãƒªã®åˆ†æã‚°ãƒ©ãƒ•
        st.markdown("#### ğŸ“ˆ è©³ç´°åˆ†æãƒãƒ£ãƒ¼ãƒˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æ„Ÿæƒ…åˆ†å¸ƒ
            df_results['sentiment_label'] = df_results['SENTIMENT_SCORE'].apply(
                lambda x: 'ãƒã‚¸ãƒ†ã‚£ãƒ–' if x > 0.1 else ('ãƒã‚¬ãƒ†ã‚£ãƒ–' if x < -0.1 else 'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«')
            )
            sentiment_counts = df_results['sentiment_label'].value_counts()
            fig = px.pie(
                values=sentiment_counts.values,
                names=sentiment_counts.index,
                title="æ„Ÿæƒ…åˆ†å¸ƒ",
                color_discrete_map={
                    'ãƒã‚¸ãƒ†ã‚£ãƒ–': '#2E8B57',
                    'ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«': '#FFD700', 
                    'ãƒã‚¬ãƒ†ã‚£ãƒ–': '#DC143C'
                }
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
            category_sentiment = df_results.groupby('CATEGORY')['SENTIMENT_SCORE'].mean().reset_index()
            fig = px.bar(
                category_sentiment,
                x='CATEGORY',
                y='SENTIMENT_SCORE',
                title="ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢",
                labels={"CATEGORY": "ã‚«ãƒ†ã‚´ãƒª", "SENTIMENT_SCORE": "å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢"},
                color='SENTIMENT_SCORE',
                color_continuous_scale='RdYlGn'
            )
            fig.add_hline(y=0, line_dash="dash", line_color="black", annotation_text="ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«")
            st.plotly_chart(fig, use_container_width=True)
        
        # ãƒãƒ£ãƒãƒ«åˆ¥åˆ†æ
        col1, col2 = st.columns(2)
        
        with col1:
            # ãƒãƒ£ãƒãƒ«åˆ¥ä»¶æ•°
            channel_counts = df_results['PURCHASE_CHANNEL'].value_counts()
            fig = px.bar(
                x=channel_counts.index,
                y=channel_counts.values,
                title="è³¼å…¥ãƒãƒ£ãƒãƒ«åˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•°",
                labels={"x": "è³¼å…¥ãƒãƒ£ãƒãƒ«", "y": "ä»¶æ•°"}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ãƒãƒ£ãƒãƒ«åˆ¥å¹³å‡è©•ä¾¡ã¨æ„Ÿæƒ…ã‚¹ã‚³ã‚¢
            channel_analysis = df_results.groupby('PURCHASE_CHANNEL').agg({
                'RATING': 'mean',
                'SENTIMENT_SCORE': 'mean'
            }).reset_index()
            
            fig = px.scatter(
                channel_analysis,
                x='RATING',
                y='SENTIMENT_SCORE',
                size=[len(df_results[df_results['PURCHASE_CHANNEL'] == ch]) for ch in channel_analysis['PURCHASE_CHANNEL']],
                hover_name='PURCHASE_CHANNEL',
                title="ãƒãƒ£ãƒãƒ«åˆ¥ï¼šè©•ä¾¡ vs æ„Ÿæƒ…ã‚¹ã‚³ã‚¢",
                labels={"RATING": "å¹³å‡è©•ä¾¡", "SENTIMENT_SCORE": "å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢"}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æ
        st.markdown("#### ğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æ")
        
        # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
        analysis_category = st.selectbox(
            "è©³ç´°åˆ†æã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ:",
            ["å…¨ä½“æ¦‚è¦"] + sorted(df_results['CATEGORY'].unique().tolist()),
            key="analysis_category"
        )
        
        if analysis_category == "å…¨ä½“æ¦‚è¦":
            # å…¨ä½“ã‚µãƒãƒªãƒ¼
            st.markdown("##### ğŸ” å…¨ä½“åˆ†æã‚µãƒãƒªãƒ¼")
            
            # æ„Ÿæƒ…åˆ¥ä¸Šä½ãƒ¬ãƒ“ãƒ¥ãƒ¼
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸ˜Š æœ€ã‚‚ãƒã‚¸ãƒ†ã‚£ãƒ–ãªãƒ¬ãƒ“ãƒ¥ãƒ¼**")
                most_positive = df_results.loc[df_results['SENTIMENT_SCORE'].idxmax()]
                st.write(f"æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {most_positive['SENTIMENT_SCORE']:.3f}")
                st.write(f"ã‚«ãƒ†ã‚´ãƒª: {most_positive['CATEGORY']}")
                st.write(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼: {most_positive['REVIEW_TEXT'][:100]}...")
            
            with col2:
                st.markdown("**ğŸ˜ æœ€ã‚‚ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªãƒ¬ãƒ“ãƒ¥ãƒ¼**")
                df_neutral = df_results[abs(df_results['SENTIMENT_SCORE']) < 0.1]
                if not df_neutral.empty:
                    most_neutral = df_neutral.loc[df_neutral['SENTIMENT_SCORE'].abs().idxmin()]
                    st.write(f"æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {most_neutral['SENTIMENT_SCORE']:.3f}")
                    st.write(f"ã‚«ãƒ†ã‚´ãƒª: {most_neutral['CATEGORY']}")
                    st.write(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼: {most_neutral['REVIEW_TEXT'][:100]}...")
                else:
                    st.write("ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“")
            
            with col3:
                st.markdown("**ğŸ˜ æœ€ã‚‚ãƒã‚¬ãƒ†ã‚£ãƒ–ãªãƒ¬ãƒ“ãƒ¥ãƒ¼**")
                most_negative = df_results.loc[df_results['SENTIMENT_SCORE'].idxmin()]
                st.write(f"æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {most_negative['SENTIMENT_SCORE']:.3f}")
                st.write(f"ã‚«ãƒ†ã‚´ãƒª: {most_negative['CATEGORY']}")
                st.write(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼: {most_negative['REVIEW_TEXT'][:100]}...")
        
        else:
            # ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®è©³ç´°åˆ†æ
            category_data = df_results[df_results['CATEGORY'] == analysis_category]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(category_data)}ä»¶")
            with col2:
                avg_rating = category_data['RATING'].mean()
                st.metric("å¹³å‡è©•ä¾¡", f"{avg_rating:.2f}")
            with col3:
                avg_sentiment = category_data['SENTIMENT_SCORE'].mean()
                st.metric("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{avg_sentiment:.3f}")
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã¨åŒæ§˜ã®å®Ÿè£…ï¼‰
            items_per_page_6 = st.slider("1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®è¡¨ç¤ºä»¶æ•°:", 5, 50, 10, key="items_per_page_6")
            total_pages_6 = max(1, (len(category_data) - 1) // items_per_page_6 + 1)
            
            if total_pages_6 > 1:
                current_page_6 = st.selectbox(
                    f"ãƒšãƒ¼ã‚¸é¸æŠ (å…¨{total_pages_6}ãƒšãƒ¼ã‚¸):",
                    range(1, total_pages_6 + 1),
                    key="current_page_6"
                )
            else:
                current_page_6 = 1
            
            # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            start_idx_6 = (current_page_6 - 1) * items_per_page_6
            end_idx_6 = start_idx_6 + items_per_page_6
            page_data_6 = category_data.iloc[start_idx_6:end_idx_6]
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥AIè¦ç´„ã®è¡¨ç¤º
            st.markdown(f"##### ğŸ¤– {analysis_category} ã‚«ãƒ†ã‚´ãƒªã®AI_SUMMARIZE_AGGè¦ç´„")
            if 'category_summaries' in st.session_state:
                df_summaries = st.session_state['category_summaries']
                category_summaries = df_summaries[df_summaries['CATEGORY'] == analysis_category]
                
                for _, summary_row in category_summaries.iterrows():
                    with st.info(f"**{summary_row['PURCHASE_CHANNEL']}ãƒãƒ£ãƒãƒ«**: {summary_row['CATEGORY_SUMMARY']}"):
                        pass
            
            # ã‚«ãƒ†ã‚´ãƒªå†…ã®å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
            st.markdown(f"##### ğŸ“ {analysis_category} ã‚«ãƒ†ã‚´ãƒªã®ãƒ¬ãƒ“ãƒ¥ãƒ¼è©³ç´°")
            for _, row in page_data_6.iterrows():
                sentiment = row['SENTIMENT_SCORE']
                if sentiment > 0.1:
                    sentiment_emoji = "ğŸ˜Š"
                    sentiment_label = "ãƒã‚¸ãƒ†ã‚£ãƒ–"
                elif sentiment < -0.1:
                    sentiment_emoji = "ğŸ˜"
                    sentiment_label = "ãƒã‚¬ãƒ†ã‚£ãƒ–"
                else:
                    sentiment_emoji = "ğŸ˜"
                    sentiment_label = "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"
                
                with st.expander(f"{sentiment_emoji} {sentiment_label} ({sentiment:.2f}) | è©•ä¾¡: {row['RATING']} | {row['PURCHASE_CHANNEL']}"):
                    st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼ID**: {row['REVIEW_ID']}")
                    st.write(f"**ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹**: {row['REVIEW_TEXT']}")
                    
                    # è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒãƒ£ãƒãƒ«ã®é›†ç´„è¦ç´„ã‚’è¡¨ç¤º
                    if 'category_summaries' in st.session_state:
                        df_summaries = st.session_state['category_summaries']
                        matching_summary = df_summaries[
                            (df_summaries['CATEGORY'] == row['CATEGORY']) & 
                            (df_summaries['PURCHASE_CHANNEL'] == row['PURCHASE_CHANNEL'])
                        ]
                        if not matching_summary.empty:
                            st.write(f"**ã“ã®ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒãƒ£ãƒãƒ«ã®AIé›†ç´„è¦ç´„**: {matching_summary.iloc[0]['CATEGORY_SUMMARY']}")

section_6_integrated()

st.markdown("---")
st.subheader("ğŸ¯ Step2 å®Œäº†ï¼")
st.success("""
âœ… **AISQLæ©Ÿèƒ½ã‚’ä½¿ã£ãŸé¡§å®¢ã®å£°åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼**

**ä½¿ç”¨ã—ãŸAISQLæ©Ÿèƒ½:**
- `AI_CLASSIFY`: ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«åˆ†é¡ï¼ˆå…¨ä»¶å¯¾è±¡ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°åˆ†æï¼‰
- `AI_FILTER`: ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå…¨ä»¶å¯¾è±¡ãƒ»ãƒãƒƒãƒç‡å¯è¦–åŒ–ï¼‰
- `AI_AGG`: è³¼å…¥ãƒãƒ£ãƒãƒ«åˆ¥é›†ç´„åˆ†æï¼ˆæ—¥æœ¬èªç¿»è¨³ä»˜ãï¼‰
- `AI_SIMILARITY`: é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¤œå‡ºï¼ˆå…¨ä»¶å¯¾è±¡ãƒ»åˆ†å¸ƒå¯è¦–åŒ–ï¼‰
- `AI_SUMMARIZE_AGG`: ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒãƒ£ãƒãƒ«åˆ¥é›†ç´„è¦ç´„ï¼ˆè¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åŠ¹ç‡çš„ã«è¦ç´„ï¼‰
- å¾“æ¥æ©Ÿèƒ½: `SENTIMENT`ï¼ˆæ„Ÿæƒ…åˆ†æï¼‰

**åˆ†æã®ä¾¡å€¤:**
- å…¨ä»¶ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ­£ç¢ºãªåˆ†æ
- ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ»ãƒãƒ£ãƒãƒ«åˆ¥ã®æ·±æ˜ã‚Šåˆ†æ
- æ„Ÿæƒ…åˆ†æã«ã‚ˆã‚‹é¡§å®¢æº€è¶³åº¦ã®å¯è¦–åŒ–
- é¡ä¼¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹
- AI_SUMMARIZE_AGGã«ã‚ˆã‚‹è¤‡æ•°ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åŠ¹ç‡çš„ãªé›†ç´„è¦ç´„
""")

st.info("ğŸ’¡ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Step3ã§ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å®Ÿè£…ã‚’å­¦ç¿’ã—ã¾ã™ã€‚")

st.markdown("---")
st.markdown(f"**Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2 | Step2: é¡§å®¢ã®å£°åˆ†æ**") 
