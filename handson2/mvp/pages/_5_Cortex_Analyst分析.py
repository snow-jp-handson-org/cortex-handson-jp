# =========================================================
# Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2
# AIã‚’ç”¨ã„ãŸé¡§å®¢ã®å£°åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# Step5: Cortex Analyståˆ†æ
# =========================================================
# æ¦‚è¦: Cortex Analystã‚’ä½¿ã£ãŸè‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿åˆ†æ
# ç‰¹å¾´: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã¨YMLãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ã«å¯¾å¿œã—ãŸé«˜ç²¾åº¦SQLè‡ªå‹•ç”Ÿæˆ
# ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½: Cortex Analyst APIã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
# =========================================================
# Created by Tsubasa Kanno @Snowflake
# æœ€çµ‚æ›´æ–°: 2025/06/16
# =========================================================

import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from snowflake.snowpark.context import get_active_session
from datetime import datetime

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide")

# =========================================================
# Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³æ¥ç¶š
# =========================================================
@st.cache_resource
def get_snowflake_session():
    """Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    return get_active_session()

session = get_snowflake_session()

# =========================================================
# è¨­å®šå€¤ï¼ˆå®šæ•°ï¼‰
# =========================================================
# åˆ©ç”¨å¯èƒ½ãªLLMãƒ¢ãƒ‡ãƒ«
LLM_MODELS = [
    "llama4-maverick",
    "claude-4-sonnet", 
    "mistral-large2"
]

# Cortex Analyst APIã®è¨­å®š
ANALYST_API_ENDPOINT = "/api/v2/cortex/analyst/message"
ANALYST_API_TIMEOUT = 50  # ç§’

# ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
SEMANTIC_MODEL_STAGE = "SEMANTIC_MODEL_STAGE"

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'selected_llm_model' not in st.session_state:
    st.session_state.selected_llm_model = LLM_MODELS[0]

# =========================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================================================
def check_table_exists(table_name: str) -> bool:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    try:
        session.sql(f"SELECT 1 FROM {table_name} LIMIT 1").collect()
        return True
    except:
        return False

def get_table_count(table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
    try:
        result = session.sql(f"SELECT COUNT(*) as count FROM {table_name}").collect()
        return result[0]['COUNT']
    except:
        return 0

def get_all_semantic_models() -> list:
    """åˆ©ç”¨å¯èƒ½ãªã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
    models = []
    
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã®å–å¾—
    try:
        semantic_views = session.sql("SHOW SEMANTIC VIEWS").collect()
        for view in semantic_views:
            view_name = view['name']
            models.append({
                "display_name": f"[ãƒ“ãƒ¥ãƒ¼] {view_name}",
                "actual_name": view_name,
                "type": "semantic_view"
            })
    except Exception:
        pass
    
    # YMLãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
    try:
        yml_files = session.sql(f"LIST @{SEMANTIC_MODEL_STAGE}").collect()
        for file_info in yml_files:
            file_name = file_info['name']
            if file_name.lower().endswith('.yml') or file_name.lower().endswith('.yaml'):
                file_name_only = file_name.split('/')[-1]
                actual_path = f"@{SEMANTIC_MODEL_STAGE}/{file_name_only}"
                models.append({
                    "display_name": f"[YML] {file_name_only}",
                    "actual_name": actual_path,
                    "type": "semantic_model_file"
                })
    except Exception:
        pass
    
    return models

def get_model_info_from_display_name(display_name: str, models_list: list) -> dict:
    """è¡¨ç¤ºåã‹ã‚‰å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
    for model in models_list:
        if model["display_name"] == display_name:
            return {
                "actual_name": model["actual_name"],
                "type": model["type"]
            }
    return None

def execute_cortex_analyst_query(question: str, model_info: dict) -> dict:
    """Cortex Analyst APIã‚’ä½¿ç”¨ã—ã¦è‡ªç„¶è¨€èªè³ªå•ã‚’åˆ†æ"""
    try:
        messages = [
            {
                "role": "user",
                "content": [{"type": "text", "text": question}]
            }
        ]
        
        request_body = {"messages": messages}
        
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
        if model_info["type"] == "semantic_view":
            request_body["semantic_view"] = model_info["actual_name"]
        else:
            request_body["semantic_model_file"] = model_info["actual_name"]
        
        # Cortex Analyst APIå‘¼ã³å‡ºã—
        try:
            import _snowflake
            resp = _snowflake.send_snow_api_request(
                "POST",
                ANALYST_API_ENDPOINT,
                {},
                {},
                request_body,
                None,
                ANALYST_API_TIMEOUT * 1000,
            )
            
            if resp["status"] < 400:
                response_data = json.loads(resp["content"])
                if "message" in response_data and "content" in response_data["message"]:
                    content_list = response_data["message"]["content"]
                    
                    response_text = ""
                    sql_query = ""
                    result_data = None
                    
                    for item in content_list:
                        if item["type"] == "text":
                            response_text += item["text"] + "\n\n"
                        elif item["type"] == "sql":
                            sql_query = item["statement"]
                    
                    # è‹±èªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ—¥æœ¬èªã«ç¿»è¨³
                    if response_text:
                        try:
                            translated_response = session.sql("""
                                SELECT SNOWFLAKE.CORTEX.TRANSLATE(?, 'en', 'ja') as translated
                            """, params=[response_text.strip()]).collect()[0]['TRANSLATED']
                            response_text = translated_response
                        except Exception:
                            pass
                    
                    # SQLã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                    try:
                        if sql_query and sql_query.strip():
                            result_data = session.sql(sql_query).to_pandas()
                        else:
                            result_data = pd.DataFrame()
                    except Exception as sql_error:
                        return {
                            "success": False,
                            "sql": sql_query,
                            "data": None,
                            "response_text": response_text,
                            "message": f"SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(sql_error)}"
                        }
                    
                    return {
                        "success": True,
                        "sql": sql_query,
                        "data": result_data,
                        "response_text": response_text.strip(),
                        "message": "åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ"
                    }
                else:
                    raise Exception("APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼ãŒä¸æ­£ã§ã™")
            else:
                error_content = json.loads(resp["content"])
                error_msg = f"APIã‚¨ãƒ©ãƒ¼ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {resp['status']}): {error_content.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                raise Exception(error_msg)
        
        except ImportError:
            return {
                "success": False,
                "sql": "",
                "data": None,
                "response_text": "",
                "message": "Cortex Analyst APIã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚Streamlit in Snowflakeç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
            }
        
    except Exception as e:
        return {
            "success": False,
            "sql": "",
            "data": None,
            "response_text": "",
            "message": f"Cortex Analystã‚¨ãƒ©ãƒ¼: {str(e)}"
        }

# =========================================================
# ã‚·ãƒ³ãƒ—ãƒ«ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚°ãƒ©ãƒ•æ©Ÿèƒ½
# =========================================================
@st.fragment
def create_customizable_graph(df: pd.DataFrame, unique_key: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    if df.empty:
        st.warning("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.subheader("ğŸ“Š ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚°ãƒ©ãƒ•")
    
    # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã®è¡¨ç¤º
    numeric_cols = []
    text_cols = []
    
    for col in df.columns:
        # æ•°å€¤ã¨ã—ã¦æ‰±ãˆã‚‹ã‹ãƒ†ã‚¹ãƒˆ
        try:
            pd.to_numeric(df[col].dropna().iloc[:3], errors='raise')
            numeric_cols.append(col)
        except (ValueError, TypeError):
            text_cols.append(col)
    
    st.info(f"ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ x {len(df.columns)}åˆ— | æ•°å€¤åˆ—: {len(numeric_cols)}å€‹ | ãƒ†ã‚­ã‚¹ãƒˆåˆ—: {len(text_cols)}å€‹")
    
    # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã®é¸æŠ
    graph_type = st.selectbox(
        "ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
        ["æ£’ã‚°ãƒ©ãƒ•", "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•", "æ•£å¸ƒå›³", "å††ã‚°ãƒ©ãƒ•", "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ "],
        key=f"{unique_key}_graph_type"
    )
    
    # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®š
    if graph_type in ["æ£’ã‚°ãƒ©ãƒ•", "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•", "æ•£å¸ƒå›³"]:
        col1, col2 = st.columns(2)
        
        with col1:
            x_axis = st.selectbox("Xè»¸ã‚’é¸æŠ", df.columns, key=f"{unique_key}_x_axis")
        
        with col2:
            y_axis = st.selectbox("Yè»¸ã‚’é¸æŠ", df.columns, key=f"{unique_key}_y_axis")
        
        # è‰²åˆ†ã‘ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        color_options = ["ãªã—"] + [col for col in df.columns if col not in [x_axis, y_axis]]
        color_option = st.selectbox("è‰²åˆ†ã‘é …ç›®ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰", color_options, key=f"{unique_key}_color")
        color_col = None if color_option == "ãªã—" else color_option
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ•°å€¤å¤‰æ›ï¼ˆå£²ä¸Šãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰
        display_df = df.copy()
        if y_axis in numeric_cols or 'sales' in y_axis.lower() or 'å£²ä¸Š' in y_axis.lower():
            try:
                # ã‚«ãƒ³ãƒé™¤å»ã¨æ•°å€¤å¤‰æ›
                if display_df[y_axis].dtype == 'object':
                    display_df[y_axis] = display_df[y_axis].astype(str).str.replace(',', '').str.replace('Â¥', '')
                    display_df[y_axis] = pd.to_numeric(display_df[y_axis], errors='coerce')
            except:
                pass
        
        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
        try:
            if graph_type == "æ£’ã‚°ãƒ©ãƒ•":
                fig = px.bar(display_df, x=x_axis, y=y_axis, color=color_col, 
                           title=f"{x_axis}ã”ã¨ã®{y_axis}")
            elif graph_type == "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•":
                fig = px.line(display_df, x=x_axis, y=y_axis, color=color_col, 
                            title=f"{y_axis}ã®æ¨ç§»", markers=True)
            else:  # æ•£å¸ƒå›³
                fig = px.scatter(display_df, x=x_axis, y=y_axis, color=color_col, 
                               title=f"{x_axis} vs {y_axis}")
            
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True, key=f"{unique_key}_main_chart")
            
        except Exception as e:
            st.error(f"ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            
    elif graph_type == "å††ã‚°ãƒ©ãƒ•":
        col1, col2 = st.columns(2)
        
        with col1:
            name_col = st.selectbox("ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’é¸æŠ", text_cols if text_cols else df.columns,
                                  key=f"{unique_key}_name_col")
        
        with col2:
            value_col = st.selectbox("å€¤ã®åˆ—ã‚’é¸æŠ", numeric_cols if numeric_cols else df.columns,
                                   key=f"{unique_key}_value_col")
        
        try:
            # æ•°å€¤å¤‰æ›
            display_df = df.copy()
            if display_df[value_col].dtype == 'object':
                display_df[value_col] = display_df[value_col].astype(str).str.replace(',', '').str.replace('Â¥', '')
                display_df[value_col] = pd.to_numeric(display_df[value_col], errors='coerce')
            
            # å††ã‚°ãƒ©ãƒ•ç”Ÿæˆ
            pie_df = display_df.groupby(name_col)[value_col].sum().reset_index()
            fig = px.pie(pie_df, names=name_col, values=value_col, 
                        title=f"{name_col}ã”ã¨ã®{value_col}ã®å‰²åˆ")
            st.plotly_chart(fig, use_container_width=True, key=f"{unique_key}_pie_chart")
            
        except Exception as e:
            st.error(f"å††ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            
    elif graph_type == "ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ":
        hist_col = st.selectbox("åˆ†å¸ƒã‚’è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ", numeric_cols if numeric_cols else df.columns,
                              key=f"{unique_key}_hist_col")
        
        try:
            # æ•°å€¤å¤‰æ›
            display_df = df.copy()
            if display_df[hist_col].dtype == 'object':
                display_df[hist_col] = display_df[hist_col].astype(str).str.replace(',', '').str.replace('Â¥', '')
                display_df[hist_col] = pd.to_numeric(display_df[hist_col], errors='coerce')
            
            fig = px.histogram(display_df, x=hist_col, title=f"{hist_col}ã®åˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True, key=f"{unique_key}_hist_chart")
            
        except Exception as e:
            st.error(f"ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")

# =========================================================
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸
# =========================================================
st.title("ğŸ“ˆ Step5: Cortex Analyståˆ†æ")
st.header("ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªç„¶è¨€èªã§åˆ†æã™ã‚‹é«˜åº¦ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

st.markdown("""
ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€Snowflake Cortex Analystã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½ã‚’ä½“é¨“ã§ãã¾ã™ã€‚
Step3ãƒ»Step4ã¨ã®é•ã„ã¯ã€**ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã¾ãŸã¯YMLãƒ•ã‚¡ã‚¤ãƒ«**ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ­£ç¢ºã§ä¿¡é ¼æ€§ã®é«˜ã„SQLç”ŸæˆãŒå¯èƒ½ãªç‚¹ã§ã™ã€‚

ğŸš€ **è‡ªå‹•æ¤œå‡ºæ©Ÿèƒ½**: åˆ©ç”¨å¯èƒ½ãªã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã¨YMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œå‡ºã—ã€çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§é¸æŠã§ãã¾ã™ã€‚
ğŸ“Š **ã‚«ã‚¹ã‚¿ãƒ ã‚°ãƒ©ãƒ•**: ãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªç”±ã«ã‚°ãƒ©ãƒ•ã‚’è¨­å®šã§ãã€å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’æ­£ç¢ºã«å¯è¦–åŒ–ã§ãã¾ã™ã€‚
""")

# =========================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# =========================================================
st.sidebar.header("âš™ï¸ Analystè¨­å®š")

# LLMãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
selected_llm_model = st.sidebar.selectbox(
    "LLMãƒ¢ãƒ‡ãƒ«:",
    LLM_MODELS,
    index=LLM_MODELS.index(st.session_state.selected_llm_model),
    help="Cortex Analystã§ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
)

if selected_llm_model != st.session_state.selected_llm_model:
    st.session_state.selected_llm_model = selected_llm_model

# å¯è¦–åŒ–è¨­å®š
enable_charts = st.sidebar.checkbox(
    "ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚°ãƒ©ãƒ•è¡¨ç¤º",
    value=True,
    help="åˆ†æçµæœã«å¯¾ã—ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚°ãƒ©ãƒ•è¨­å®šã‚’è¡¨ç¤º"
)

# ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«è¨­å®š")

all_semantic_models = get_all_semantic_models()

if all_semantic_models:
    selected_semantic_model = st.sidebar.selectbox(
        "ä½¿ç”¨ã™ã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«:",
        [model["display_name"] for model in all_semantic_models],
        index=0,
        help="åˆ†æã«ä½¿ç”¨ã™ã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"
    )
    
    st.sidebar.success("âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«é¸æŠæ¸ˆã¿")
    
    model_info = get_model_info_from_display_name(selected_semantic_model, all_semantic_models)
    if model_info:
        if model_info["type"] == "semantic_view":
            st.sidebar.code(model_info["actual_name"], language="sql")
            st.sidebar.caption("ğŸ—ï¸ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼å½¢å¼")
        else:
            st.sidebar.code(model_info["actual_name"], language="yaml")
            st.sidebar.caption("ğŸ“„ YMLãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼")
else:
    st.sidebar.error("âŒ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    selected_semantic_model = None
    model_info = None

st.sidebar.info("""
**Cortex Analystã®ä»•çµ„ã¿:**
1. ğŸ§  è‡ªç„¶è¨€èªã®è³ªå•ã‚’ç†è§£
2. ğŸ“‹ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’å‚ç…§
3. ğŸ”§ æœ€é©ãªSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
4. ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§å®Ÿè¡Œ
5. ğŸ“ˆ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãªã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–
""")

st.markdown("---")

# =========================================================
# ãƒ‡ãƒ¼ã‚¿çŠ¶æ³ç¢ºèª
# =========================================================
st.subheader("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ç¢ºèª")

col1, col2, col3 = st.columns(3)

required_tables = {
    "RETAIL_DATA_WITH_PRODUCT_MASTER": "åº—èˆ—å£²ä¸Šãƒ‡ãƒ¼ã‚¿",
    "EC_DATA_WITH_PRODUCT_MASTER": "ECå£²ä¸Šãƒ‡ãƒ¼ã‚¿"
}

with col1:
    st.markdown("#### ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")
    total_records = 0
    for table_name, description in required_tables.items():
        exists = check_table_exists(table_name)
        count = get_table_count(table_name) if exists else 0
        total_records += count
        status_icon = "âœ…" if exists else "âŒ"
        st.write(f"{status_icon} {description}: **{count:,}ä»¶**")
    
    if total_records > 0:
        st.success(f"åˆè¨ˆ {total_records:,} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½")
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

with col2:
    st.markdown("#### ğŸ§  Cortex Analyst")
    if selected_semantic_model and model_info:
        st.success("âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«: åˆ©ç”¨å¯èƒ½")
        st.success("âœ… Cortex Analyst API: åˆ©ç”¨å¯èƒ½")
        
        if model_info["type"] == "semantic_view":
            st.info("ğŸ—ï¸ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼å½¢å¼ã‚’ä½¿ç”¨ä¸­")
        else:
            st.info("ğŸ“„ YMLãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ä½¿ç”¨ä¸­")
    else:
        st.error("âŒ ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«: æœªè¨­å®š")
        st.warning("âŒ Cortex Analyst API: åˆ©ç”¨ä¸å¯")

with col3:
    st.markdown("#### âš™ï¸ åˆ†æè¨­å®š")
    st.write(f"ğŸ¤– **LLMãƒ¢ãƒ‡ãƒ«**: {st.session_state.selected_llm_model}")
    st.write(f"ğŸ“Š **ã‚«ã‚¹ã‚¿ãƒ ã‚°ãƒ©ãƒ•**: {'æœ‰åŠ¹' if enable_charts else 'ç„¡åŠ¹'}")
    if all_semantic_models:
        st.write(f"ğŸ“‹ **é¸æŠãƒ¢ãƒ‡ãƒ«**: {selected_semantic_model}")

# å‰ææ¡ä»¶ã®ãƒã‚§ãƒƒã‚¯
if not selected_semantic_model or not model_info:
    st.error(f"""
    âš ï¸ **ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“**
    
    Cortex Analystã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã¾ãŸã¯YMLãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚
    """)
    st.stop()

st.markdown("---")

# =========================================================
# è‡ªç„¶è¨€èªåˆ†æãƒãƒ£ãƒƒãƒˆ
# =========================================================
st.subheader("ğŸ” è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿åˆ†æ")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "analyst_chat_history" not in st.session_state:
    st.session_state.analyst_chat_history = []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
if st.session_state.analyst_chat_history:
    st.markdown("#### ğŸ’­ åˆ†æå±¥æ­´")
    for i, message in enumerate(st.session_state.analyst_chat_history):
        if message["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.write(message["content"])
        elif message["role"] == "analyst":
            with st.chat_message("assistant", avatar="ğŸ“Š"):
                st.write(message["content"])
                
                # åˆ†æçµæœã®è¡¨ç¤º
                if "result" in message and message["result"]["success"]:
                    if message["result"]["data"] is not None and not message["result"]["data"].empty:
                        st.dataframe(message["result"]["data"], use_container_width=True)
                        
                        # ã‚°ãƒ©ãƒ•è¨­å®šã®è¡¨ç¤º
                        if enable_charts:
                            st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã—ãŸã€‚ä¸‹è¨˜ã§ã‚°ãƒ©ãƒ•ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™ã€‚")
                            create_customizable_graph(message["result"]["data"], f"msg_{i}")
                    
                    # ç”Ÿæˆã•ã‚ŒãŸSQLã®è¡¨ç¤º
                    if message["result"]["sql"]:
                        with st.expander("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸSQL"):
                            st.code(message["result"]["sql"], language="sql")

# è³ªå•å…¥åŠ›ã‚¨ãƒªã‚¢
col1, col2 = st.columns([4, 1])

with col1:
    user_question = st.text_input(
        "ğŸ’¬ ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„:",
        key="analyst_input",
        placeholder="ä¾‹: å£²ä¸ŠTOP10ã®å•†å“ã¨ãã®å£²ä¸Šé‡‘é¡ã‚’æ•™ãˆã¦"
    )

with col2:
    st.write("")
    clear_chat = st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", help="ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢")

# åˆ†æå®Ÿè¡Œå‡¦ç†
if st.button("ğŸš€ Cortex Analyståˆ†æ", type="primary", use_container_width=True):
    if user_question:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã‚’å±¥æ­´ã«è¿½åŠ 
        st.session_state.analyst_chat_history.append({"role": "user", "content": user_question})
        
        with st.spinner("ğŸ§  Cortex AnalystãŒåˆ†æä¸­..."):
            # Cortex Analyståˆ†æã‚’å®Ÿè¡Œ
            current_model_info = get_model_info_from_display_name(selected_semantic_model, all_semantic_models)
            result = execute_cortex_analyst_query(user_question, current_model_info)
            
            if result["success"]:
                response_text = result.get("response_text", "åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.analyst_chat_history.append({
                    "role": "analyst", 
                    "content": response_text,
                    "result": result
                })
            else:
                error_message = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\n**ã‚¨ãƒ©ãƒ¼å†…å®¹**: {result['message']}"
                st.session_state.analyst_chat_history.append({
                    "role": "analyst", 
                    "content": error_message,
                    "result": result
                })
        
        st.rerun()

# ãƒãƒ£ãƒƒãƒˆã‚¯ãƒªã‚¢å‡¦ç†
if clear_chat:
    st.session_state.analyst_chat_history = []
    st.rerun()

# =========================================================
# ã‚ˆãã‚ã‚‹åˆ†æãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
# =========================================================
st.markdown("---")
st.subheader("ğŸ’¡ ã‚ˆãã‚ã‚‹åˆ†æãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")

analysis_templates = [
    "å£²ä¸ŠTOP10ã®å•†å“ã¨ãã®å£²ä¸Šé‡‘é¡ã‚’æ•™ãˆã¦",
    "æœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’æ™‚ç³»åˆ—ã§è¦‹ã›ã¦",
    "åº—èˆ—ã¨ECã®å£²ä¸Šã‚’æ¯”è¼ƒã—ã¦",
    "å•†å“åˆ¥ã®å£²ä¸Šãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œã£ã¦"
]

col1, col2 = st.columns(2)

for i, question in enumerate(analysis_templates):
    with col1 if i % 2 == 0 else col2:
        if st.button(question, key=f"template_{i}", use_container_width=True):
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè³ªå•ã‚’å®Ÿè¡Œ
            st.session_state.analyst_chat_history.append({"role": "user", "content": question})
            
            with st.spinner("ğŸ§  Cortex AnalystãŒåˆ†æä¸­..."):
                template_model_info = get_model_info_from_display_name(selected_semantic_model, all_semantic_models)
                result = execute_cortex_analyst_query(question, template_model_info)
                
                if result["success"]:
                    response_text = result.get("response_text", "åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    st.session_state.analyst_chat_history.append({
                        "role": "analyst", 
                        "content": response_text,
                        "result": result
                    })
                else:
                    error_message = f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {result['message']}"
                    st.session_state.analyst_chat_history.append({
                        "role": "analyst", 
                        "content": error_message,
                        "result": result
                    })
            
            st.rerun()

# =========================================================
# Step5 å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# =========================================================
st.markdown("---")
st.subheader("ğŸ¯ Step5 å®Œäº†ï¼")
st.success("""
âœ… **Cortex Analyståˆ†æã®å®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸï¼**

**å®Ÿè£…ã—ãŸæ©Ÿèƒ½:**
- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã¨YMLãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•æ¤œå‡ºãƒ»çµ±åˆé¸æŠ
- ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸé«˜ç²¾åº¦SQLç”Ÿæˆ
- è‡ªç„¶è¨€èªã«ã‚ˆã‚‹ä¼æ¥­ãƒ‡ãƒ¼ã‚¿åˆ†æ
- ã‚·ãƒ³ãƒ—ãƒ«ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚°ãƒ©ãƒ•æ©Ÿèƒ½
- ã‚ˆãã‚ã‚‹åˆ†æãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- åˆ†æå±¥æ­´ã¨çµ±è¨ˆæƒ…å ±
""")

st.info("ğŸ‰ **ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—å®Œäº†**: å…¨5ã‚¹ãƒ†ãƒƒãƒ—ã®Snowflake Cortex HandsonãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("**Snowflake Cortex Handson ã‚·ãƒŠãƒªã‚ª#2 | Step5: Cortex Analyståˆ†æ**")
